{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juncollin/StableDiffusionTrain/blob/main/stable_diffusion_vit_baseline_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MEYd45rNDkbS"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "id": "MEYd45rNDkbS"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS3ASz_PDkQy",
        "outputId": "e84e8896-54cb-4a8c-abed-c73f4f9755d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb http://packages.cloud.google.com/apt gcsfuse-focal main\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1210  100  1210    0     0  55000      0 --:--:-- --:--:-- --:--:-- 55000\n",
            "OK\n",
            "Hit:1 http://packages.cloud.google.com/apt gcsfuse-focal InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:12 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "gcsfuse is already the newest version (0.42.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!apt-get -y -q update\n",
        "!apt-get -y -q install gcsfuse"
      ],
      "id": "MS3ASz_PDkQy"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0ciWamrEHO4",
        "outputId": "cf291e56-58a3-468a-a31b-411228f36fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0501 03:30:40.642150 2023/05/01 03:30:40.642107 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0001-to-0100-of-2000\n",
            "I0501 03:30:41.251914 2023/05/01 03:30:41.251881 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0101-to-0200-of-2000\n",
            "I0501 03:30:42.564561 2023/05/01 03:30:42.564535 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0201-to-0300-of-2000\n",
            "I0501 03:30:44.475830 2023/05/01 03:30:44.475796 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0301-to-0400-of-2000\n",
            "I0501 03:30:45.084540 2023/05/01 03:30:45.084508 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0401-to-0500-of-2000\n",
            "I0501 03:30:46.397157 2023/05/01 03:30:46.397108 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0501-to-0600-of-2000\n",
            "I0501 03:30:47.908115 2023/05/01 03:30:47.908075 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0601-to-0700-of-2000\n",
            "I0501 03:30:49.732892 2023/05/01 03:30:49.732868 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0701-to-0800-of-2000\n",
            "I0501 03:30:51.136576 2023/05/01 03:30:51.136529 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0801-to-0900-of-2000\n",
            "I0501 03:30:51.950122 2023/05/01 03:30:51.950089 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0901-to-1000-of-2000\n",
            "I0501 03:30:53.364281 2023/05/01 03:30:53.364252 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1001-to-1100-of-2000\n",
            "I0501 03:30:54.689830 2023/05/01 03:30:54.689794 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1101-to-1200-of-2000\n",
            "I0501 03:30:56.010563 2023/05/01 03:30:56.010519 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1201-to-1300-of-2000\n",
            "I0501 03:30:57.440260 2023/05/01 03:30:57.440232 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1301-to-1400-of-2000\n",
            "I0501 03:30:58.134512 2023/05/01 03:30:58.134490 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1401-to-1500-of-2000\n",
            "I0501 03:30:59.444087 2023/05/01 03:30:59.444040 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1501-to-1600-of-2000\n",
            "I0501 03:31:00.757592 2023/05/01 03:31:00.757554 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1601-to-1700-of-2000\n",
            "I0501 03:31:01.464740 2023/05/01 03:31:01.464703 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1701-to-1800-of-2000\n",
            "I0501 03:31:02.779810 2023/05/01 03:31:02.779786 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1801-to-1900-of-2000\n",
            "I0501 03:31:03.390666 2023/05/01 03:31:03.390630 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1901-to-2000-of-2000\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p diffusiondb-2m-part-0001-to-0100-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-c324cdea78f230dac2b175264e4dc6e4dcc57a9b277cd8bbc57a1818\" diffusiondb-2m-part-0001-to-0100-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0101-to-0200-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-5c71117e78c220337fdbe8f8d2bd820844cc78769abf7d3219c30c2b\" diffusiondb-2m-part-0101-to-0200-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0201-to-0300-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-ad61ffa68bb93268ad6061e455b696dcda0841a00d7e27011ec2be95\" diffusiondb-2m-part-0201-to-0300-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0301-to-0400-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-2819b317a18a1b7489ac9260c8788b0b7c69e1b29e6e4acdd8b31c26\" diffusiondb-2m-part-0301-to-0400-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0401-to-0500-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-afe4bf4f2244e1bd03d6ba712ca3525e5d47bdd3a3d149bab29ac262\" diffusiondb-2m-part-0401-to-0500-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0501-to-0600-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-cef3adef8dea2941cfa7b4e97143f5efbb74b5ccaa664a735d58b3fe\" diffusiondb-2m-part-0501-to-0600-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0601-to-0700-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-5caee31e7c6bd94b71bfe64b4f6664db84c5153dc5ffaa9ec7dd047a\" diffusiondb-2m-part-0601-to-0700-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0701-to-0800-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-fea92478e733bfb9c1e69da7799318b76f0e795f36a3f68a99d9498d\" diffusiondb-2m-part-0701-to-0800-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0801-to-0900-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-836aa2ab500f4764ff2d467b3089013e86cc90a71259f86b9774dbd6\" diffusiondb-2m-part-0801-to-0900-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0901-to-1000-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-7b1cfaeebf00d55ffabcb5860594ed0dbee1c81cb947c687bc9bea07\" diffusiondb-2m-part-0901-to-1000-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1001-to-1100-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-7ade5525b556b9eea6a53cc170396cb103c4ce62be5da1df987299f2\" diffusiondb-2m-part-1001-to-1100-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1101-to-1200-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-efbb0c203baed59b1c153030b22dabac3911f216fb4e600c4208fd41\" diffusiondb-2m-part-1101-to-1200-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1201-to-1300-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-e2a5a02ef2ba304333df0e5f46fc7ec5bac8333c84b987f9a8db59f4\" diffusiondb-2m-part-1201-to-1300-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1301-to-1400-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-8107407e99743c8922e3aff60701f5e441ca268255c174d6236444c5\" diffusiondb-2m-part-1301-to-1400-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1401-to-1500-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-32281830b852935bc073a0b3b4574f664273fe9de481826c5eb4dbd4\" diffusiondb-2m-part-1401-to-1500-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1501-to-1600-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-65febcdd8da968ed3e0324d3c3c579e47c3c58c4c75c3d4ce3237710\" diffusiondb-2m-part-1501-to-1600-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1601-to-1700-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-87da7915ce494865fab64a0b7a2c393971897f127d797826c4e241bc\" diffusiondb-2m-part-1601-to-1700-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1701-to-1800-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-27b2364651e011817e8024861c33c5ac8119a058f15240afa61d932d\" diffusiondb-2m-part-1701-to-1800-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1801-to-1900-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-b1f4e4432a937463a4ac47d22628d7a30c2bc72cc690399d0c3637b2\" diffusiondb-2m-part-1801-to-1900-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1901-to-2000-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-a631c3ac53a25dfd1d447dd2b712eceef25a765464ada682d962c9fb\" diffusiondb-2m-part-1901-to-2000-of-2000\n"
      ],
      "id": "M0ciWamrEHO4"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "n_PWk8To9v5w"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# import os\n",
        "# for i in range(20):\n",
        "#   path = f'diffusiondb-2m-part-{i*100+1:04}-to-{(i+1)*100:04}-of-2000'\n",
        "#   if len(os.listdir(path)) == 0:\n",
        "#     print(f'no file in {path}')"
      ],
      "id": "n_PWk8To9v5w"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ctOxUIGP7wZ",
        "outputId": "c36cc081-df51-4c51-d3f7-61962bbce39f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘sentence-transformers-2.2.2’: File exists\n",
            "I0501 03:31:04.717223 2023/05/01 03:31:04.717168 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/sentence-transformers-2.2.2\n",
            "daemonize.Run: readFromProcess: sub-process: mountWithArgs: mountWithConn: fs.NewServer: create file system: SetUpBucket: Error in iterating through objects: storage: bucket doesn't exist\n"
          ]
        }
      ],
      "source": [
        "!mkdir sentence-transformers-2.2.2\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-ec821ef42c72f1dc80e5f037880dbdd1de86ee50475cd05aa76b46dd\" sentence-transformers-2.2.2"
      ],
      "id": "6ctOxUIGP7wZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HwcNGJ44FRx",
        "outputId": "17a07dcf-4da4-4961-c7c9-0558024264cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "stable-diffusion-image-to-prompts.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  /content/stable-diffusion-image-to-prompts.zip\n",
            "replace images/20057f34d.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "!pip install kaggle\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "f = open(\"/content/gdrive/My Drive/Colab Notebooks/Kaggle/kaggle.json\", 'r')\n",
        "json_data = json.load(f) \n",
        "os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
        "os.environ['KAGGLE_KEY'] = json_data['key']\n",
        "\n",
        "!kaggle competitions download -c stable-diffusion-image-to-prompts\n",
        "!unzip /content/stable-diffusion-image-to-prompts.zip\n",
        "\n",
        "!mkdir diffusiondb-data-cleansing\n",
        "!kaggle kernels output shoheiazuma/diffusiondb-data-cleansing -p diffusiondb-data-cleansing\n",
        "#!mkdir /content/input\n",
        "#!mv /content/stable-diffusion-image-to-prompts.zip /content/input/stable-diffusion-image-to-prompts.zip\n",
        "#!unzip /content/input/stable-diffusion-image-to-prompts.zip -d /content/input/"
      ],
      "id": "0HwcNGJ44FRx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb9cb652"
      },
      "source": [
        "# Library"
      ],
      "id": "cb9cb652"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtYsiHEjEvxR"
      },
      "outputs": [],
      "source": [
        "!pip install timm\n",
        "!pip install sentence_transformers"
      ],
      "id": "UtYsiHEjEvxR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f942bbda"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from scipy import spatial\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "from timm.utils import AverageMeter\n",
        "import sys\n",
        "#sys.path.append('../input/sentence-transformers-222/sentence-transformers')\n",
        "sys.path.append('./sentence-transformers-2.2.2/sentence-transformers')\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "f942bbda"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efbf935e"
      },
      "source": [
        "# Config"
      ],
      "id": "efbf935e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b7f198a"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    model_name = 'vit_base_patch16_224'\n",
        "    input_size = 224\n",
        "    batch_size = 64\n",
        "    num_epochs = 10\n",
        "    lr = 1e-4\n",
        "    seed = 42"
      ],
      "id": "9b7f198a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6999f593"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(CFG.seed)"
      ],
      "id": "6999f593"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bef1b8da"
      },
      "source": [
        "# Dataset"
      ],
      "id": "bef1b8da"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f96e2f5a"
      },
      "outputs": [],
      "source": [
        "class DiffusionDataset(Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = Image.open(row['filepath'])\n",
        "        image = self.transform(image)\n",
        "        prompt = row['prompt']\n",
        "        return image, prompt\n",
        "\n",
        "\n",
        "class DiffusionCollator:\n",
        "    def __init__(self):\n",
        "        self.st_model = SentenceTransformer(\n",
        "            './sentence-transformers-2.2.2/all-MiniLM-L6-v2',\n",
        "            device='cpu'\n",
        "        )\n",
        "        # self.st_model = SentenceTransformer(\n",
        "        #     '/kaggle/input/sentence-transformers-222/all-MiniLM-L6-v2',\n",
        "        #     device='cpu'\n",
        "        # )\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        images, prompts = zip(*batch)\n",
        "        images = torch.stack(images)\n",
        "        prompt_embeddings = self.st_model.encode(\n",
        "            prompts, \n",
        "            show_progress_bar=False, \n",
        "            convert_to_tensor=True\n",
        "        )\n",
        "        return images, prompt_embeddings\n",
        "    \n",
        "    \n",
        "def get_dataloaders(\n",
        "    trn_df,\n",
        "    val_df,\n",
        "    input_size,\n",
        "    batch_size\n",
        "):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    trn_dataset = DiffusionDataset(trn_df, transform)\n",
        "    val_dataset = DiffusionDataset(val_df, transform)\n",
        "    collator = DiffusionCollator()\n",
        "    \n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = DataLoader(\n",
        "        dataset=trn_dataset,\n",
        "        shuffle=True,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=True,\n",
        "        collate_fn=collator\n",
        "    )\n",
        "    dataloaders['val'] = DataLoader(\n",
        "        dataset=val_dataset,\n",
        "        shuffle=False,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=False,\n",
        "        collate_fn=collator\n",
        "    )\n",
        "    return dataloaders"
      ],
      "id": "f96e2f5a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a47897ef"
      },
      "source": [
        "# Train"
      ],
      "id": "a47897ef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b45a55d4"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(y_trues, y_preds):\n",
        "    return np.mean([\n",
        "        1 - spatial.distance.cosine(y_true, y_pred) \n",
        "        for y_true, y_pred in zip(y_trues, y_preds)\n",
        "    ])"
      ],
      "id": "b45a55d4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51afe626"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    trn_df,\n",
        "    val_df,\n",
        "    model_name,\n",
        "    input_size,\n",
        "    batch_size,\n",
        "    num_epochs,\n",
        "    lr\n",
        "):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    dataloaders = get_dataloaders(\n",
        "        trn_df,\n",
        "        val_df,\n",
        "        input_size,\n",
        "        batch_size\n",
        "    )\n",
        "\n",
        "    model = timm.create_model(\n",
        "        model_name,\n",
        "        pretrained=True,\n",
        "        num_classes=384\n",
        "    )\n",
        "    model.set_grad_checkpointing()\n",
        "    model.to(device)\n",
        "    \n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    ttl_iters = num_epochs * len(dataloaders['train'])\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=ttl_iters, eta_min=1e-6)\n",
        "    criterion = nn.CosineEmbeddingLoss()\n",
        "    \n",
        "    best_score = -1.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_meters = {\n",
        "            'loss': AverageMeter(),\n",
        "            'cos': AverageMeter(),\n",
        "        }\n",
        "        model.train()\n",
        "        for X, y in tqdm(dataloaders['train'], leave=False):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            X_out = model(X)\n",
        "            target = torch.ones(X.size(0)).to(device)\n",
        "            loss = criterion(X_out, y, target)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            trn_loss = loss.item()\n",
        "            trn_cos = cosine_similarity(\n",
        "                X_out.detach().cpu().numpy(), \n",
        "                y.detach().cpu().numpy()\n",
        "            )\n",
        "\n",
        "            train_meters['loss'].update(trn_loss, n=X.size(0))\n",
        "            train_meters['cos'].update(trn_cos, n=X.size(0))\n",
        "\n",
        "        print('Epoch {:d} / trn/loss={:.4f}, trn/cos={:.4f}'.format(\n",
        "            epoch + 1,\n",
        "            train_meters['loss'].avg,\n",
        "            train_meters['cos'].avg))\n",
        "\n",
        "        val_meters = {\n",
        "            'loss': AverageMeter(),\n",
        "            'cos': AverageMeter(),\n",
        "        }\n",
        "        model.eval()\n",
        "        for X, y in tqdm(dataloaders['val'], leave=False):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                X_out = model(X)\n",
        "                target = torch.ones(X.size(0)).to(device)\n",
        "                loss = criterion(X_out, y, target)\n",
        "\n",
        "                val_loss = loss.item()\n",
        "                val_cos = cosine_similarity(\n",
        "                    X_out.detach().cpu().numpy(), \n",
        "                    y.detach().cpu().numpy()\n",
        "                )\n",
        "\n",
        "            val_meters['loss'].update(val_loss, n=X.size(0))\n",
        "            val_meters['cos'].update(val_cos, n=X.size(0))\n",
        "\n",
        "        print('Epoch {:d} / val/loss={:.4f}, val/cos={:.4f}'.format(\n",
        "            epoch + 1,\n",
        "            val_meters['loss'].avg,\n",
        "            val_meters['cos'].avg))\n",
        "        \n",
        "        if val_meters['cos'].avg > best_score:\n",
        "            best_score = val_meters['cos'].avg\n",
        "            torch.save(model.state_dict(), f'{model_name}.pth')"
      ],
      "id": "51afe626"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G5YfwBlFgk5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./diffusiondb-data-cleansing/diffusiondb.csv')\n",
        "df.head()"
      ],
      "id": "9G5YfwBlFgk5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3Th0qCKFoc8"
      },
      "outputs": [],
      "source": [
        "df.filepath = df.filepath.str.replace('/kaggle/input', '.', regex=True)\n",
        "df.head()"
      ],
      "id": "i3Th0qCKFoc8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "564e150a"
      },
      "outputs": [],
      "source": [
        "trn_df, val_df = train_test_split(df, test_size=0.1, random_state=CFG.seed)"
      ],
      "id": "564e150a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37b51ad9"
      },
      "outputs": [],
      "source": [
        "# trn_df = df[:2]\n",
        "# val_df = df[2:4]\n",
        "# val_df"
      ],
      "id": "37b51ad9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6a1db70"
      },
      "outputs": [],
      "source": [
        "train(trn_df, val_df, CFG.model_name, CFG.input_size, CFG.batch_size, CFG.num_epochs, CFG.lr)"
      ],
      "id": "b6a1db70"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f74eabef"
      },
      "outputs": [],
      "source": [
        "# model = timm.create_model(\n",
        "#     CFG.model_name,\n",
        "#     pretrained=True,\n",
        "#     num_classes=384\n",
        "# )\n",
        "# model.load_state_dict(torch.load('{CFG.model_name}.pth'))\n",
        "\n",
        "# model.eval()\n",
        "# for X, y in tqdm(dataloaders['val'], leave=False):\n",
        "#     X, y = X.to(device), y.to(device)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         X_out = model(X)\n",
        "#         target = torch.ones(X.size(0)).to(device)\n",
        "#         loss = criterion(X_out, y, target)\n"
      ],
      "id": "f74eabef"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 30786.129377,
      "end_time": "2023-04-04T21:58:26.542178",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-04-04T13:25:20.412801",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}