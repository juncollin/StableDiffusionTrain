{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juncollin/StableDiffusionTrain/blob/main/stable_diffusion_vit_baseline_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MEYd45rNDkbS"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "id": "MEYd45rNDkbS"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MS3ASz_PDkQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da473c1c-4dda-4866-d018-6c6bea6f5b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb http://packages.cloud.google.com/apt gcsfuse-focal main\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1210  100  1210    0     0  55000      0 --:--:-- --:--:-- --:--:-- 55000\n",
            "OK\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [77.6 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:7 http://packages.cloud.google.com/apt gcsfuse-focal InRelease [5,002 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:9 http://packages.cloud.google.com/apt gcsfuse-focal/main amd64 Packages [2,217 B]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,039 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,334 kB]\n",
            "Hit:16 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,668 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,150 kB]\n",
            "Fetched 8,615 kB in 3s (3,215 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 27 not upgraded.\n",
            "Need to get 13.9 MB of archives.\n",
            "After this operation, 32.3 MB of additional disk space will be used.\n",
            "Get:1 http://packages.cloud.google.com/apt gcsfuse-focal/main amd64 gcsfuse amd64 0.42.4 [13.9 MB]\n",
            "Fetched 13.9 MB in 1s (21.1 MB/s)\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_0.42.4_amd64.deb ...\n",
            "Unpacking gcsfuse (0.42.4) ...\n",
            "Setting up gcsfuse (0.42.4) ...\n"
          ]
        }
      ],
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!apt-get -y -q update\n",
        "!apt-get -y -q install gcsfuse"
      ],
      "id": "MS3ASz_PDkQy"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M0ciWamrEHO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fec1603-da00-47da-cfa3-4e5fd96bc21e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0501 21:52:52.213159 2023/05/01 21:52:52.213122 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0001-to-0100-of-2000\n",
            "I0501 21:52:53.824529 2023/05/01 21:52:53.824489 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0101-to-0200-of-2000\n",
            "I0501 21:52:54.531828 2023/05/01 21:52:54.531792 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0201-to-0300-of-2000\n",
            "I0501 21:52:56.143665 2023/05/01 21:52:56.143631 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0301-to-0400-of-2000\n",
            "I0501 21:52:58.259339 2023/05/01 21:52:58.259312 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0401-to-0500-of-2000\n",
            "I0501 21:53:00.327933 2023/05/01 21:53:00.327901 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0501-to-0600-of-2000\n",
            "I0501 21:53:02.035698 2023/05/01 21:53:02.035664 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0601-to-0700-of-2000\n",
            "I0501 21:53:03.730679 2023/05/01 21:53:03.730648 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0701-to-0800-of-2000\n",
            "I0501 21:53:06.144582 2023/05/01 21:53:06.144543 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0801-to-0900-of-2000\n",
            "I0501 21:53:07.957150 2023/05/01 21:53:07.957123 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-0901-to-1000-of-2000\n",
            "I0501 21:53:10.069787 2023/05/01 21:53:10.069760 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1001-to-1100-of-2000\n",
            "I0501 21:53:11.683459 2023/05/01 21:53:11.683425 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1101-to-1200-of-2000\n",
            "I0501 21:53:13.296300 2023/05/01 21:53:13.296270 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1201-to-1300-of-2000\n",
            "I0501 21:53:14.905998 2023/05/01 21:53:14.905975 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1301-to-1400-of-2000\n",
            "I0501 21:53:16.319314 2023/05/01 21:53:16.319282 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1401-to-1500-of-2000\n",
            "I0501 21:53:17.728536 2023/05/01 21:53:17.728484 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1501-to-1600-of-2000\n",
            "I0501 21:53:19.339843 2023/05/01 21:53:19.339809 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1601-to-1700-of-2000\n",
            "I0501 21:53:20.955586 2023/05/01 21:53:20.955545 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1701-to-1800-of-2000\n",
            "I0501 21:53:22.669227 2023/05/01 21:53:22.669190 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1801-to-1900-of-2000\n",
            "I0501 21:53:24.284039 2023/05/01 21:53:24.283999 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/diffusiondb-2m-part-1901-to-2000-of-2000\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p diffusiondb-2m-part-0001-to-0100-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-c324cdea78f230dac2b175264e4dc6e4dcc57a9b277cd8bbc57a1818\" diffusiondb-2m-part-0001-to-0100-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0101-to-0200-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-5c71117e78c220337fdbe8f8d2bd820844cc78769abf7d3219c30c2b\" diffusiondb-2m-part-0101-to-0200-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0201-to-0300-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-ad61ffa68bb93268ad6061e455b696dcda0841a00d7e27011ec2be95\" diffusiondb-2m-part-0201-to-0300-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0301-to-0400-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-2819b317a18a1b7489ac9260c8788b0b7c69e1b29e6e4acdd8b31c26\" diffusiondb-2m-part-0301-to-0400-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0401-to-0500-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-afe4bf4f2244e1bd03d6ba712ca3525e5d47bdd3a3d149bab29ac262\" diffusiondb-2m-part-0401-to-0500-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0501-to-0600-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-cef3adef8dea2941cfa7b4e97143f5efbb74b5ccaa664a735d58b3fe\" diffusiondb-2m-part-0501-to-0600-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0601-to-0700-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-5caee31e7c6bd94b71bfe64b4f6664db84c5153dc5ffaa9ec7dd047a\" diffusiondb-2m-part-0601-to-0700-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0701-to-0800-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-fea92478e733bfb9c1e69da7799318b76f0e795f36a3f68a99d9498d\" diffusiondb-2m-part-0701-to-0800-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0801-to-0900-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-836aa2ab500f4764ff2d467b3089013e86cc90a71259f86b9774dbd6\" diffusiondb-2m-part-0801-to-0900-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-0901-to-1000-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-7b1cfaeebf00d55ffabcb5860594ed0dbee1c81cb947c687bc9bea07\" diffusiondb-2m-part-0901-to-1000-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1001-to-1100-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-7ade5525b556b9eea6a53cc170396cb103c4ce62be5da1df987299f2\" diffusiondb-2m-part-1001-to-1100-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1101-to-1200-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-efbb0c203baed59b1c153030b22dabac3911f216fb4e600c4208fd41\" diffusiondb-2m-part-1101-to-1200-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1201-to-1300-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-e2a5a02ef2ba304333df0e5f46fc7ec5bac8333c84b987f9a8db59f4\" diffusiondb-2m-part-1201-to-1300-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1301-to-1400-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-8107407e99743c8922e3aff60701f5e441ca268255c174d6236444c5\" diffusiondb-2m-part-1301-to-1400-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1401-to-1500-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-32281830b852935bc073a0b3b4574f664273fe9de481826c5eb4dbd4\" diffusiondb-2m-part-1401-to-1500-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1501-to-1600-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-65febcdd8da968ed3e0324d3c3c579e47c3c58c4c75c3d4ce3237710\" diffusiondb-2m-part-1501-to-1600-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1601-to-1700-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-87da7915ce494865fab64a0b7a2c393971897f127d797826c4e241bc\" diffusiondb-2m-part-1601-to-1700-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1701-to-1800-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-27b2364651e011817e8024861c33c5ac8119a058f15240afa61d932d\" diffusiondb-2m-part-1701-to-1800-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1801-to-1900-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-b1f4e4432a937463a4ac47d22628d7a30c2bc72cc690399d0c3637b2\" diffusiondb-2m-part-1801-to-1900-of-2000\n",
        "!mkdir -p diffusiondb-2m-part-1901-to-2000-of-2000\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-a631c3ac53a25dfd1d447dd2b712eceef25a765464ada682d962c9fb\" diffusiondb-2m-part-1901-to-2000-of-2000\n"
      ],
      "id": "M0ciWamrEHO4"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n_PWk8To9v5w"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# import os\n",
        "# for i in range(20):\n",
        "#   path = f'diffusiondb-2m-part-{i*100+1:04}-to-{(i+1)*100:04}-of-2000'\n",
        "#   if len(os.listdir(path)) == 0:\n",
        "#     print(f'no file in {path}')"
      ],
      "id": "n_PWk8To9v5w"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6ctOxUIGP7wZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5657a54-aa52-4b4f-a406-763feddb3f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I0501 21:53:25.910191 2023/05/01 21:53:25.910155 Start gcsfuse/0.42.4 (Go version go1.19.7) for app \"\" using mount point: /content/sentence-transformers-2.2.2\n"
          ]
        }
      ],
      "source": [
        "!mkdir sentence-transformers-2.2.2\n",
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 \"kds-ec821ef42c72f1dc80e5f037880dbdd1de86ee50475cd05aa76b46dd\" sentence-transformers-2.2.2"
      ],
      "id": "6ctOxUIGP7wZ"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HwcNGJ44FRx",
        "outputId": "ee1d638d-fedf-45ac-e8d9-4d6488323296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Mounted at /content/gdrive\n",
            "Downloading stable-diffusion-image-to-prompts.zip to /content\n",
            " 66% 2.00M/3.04M [00:01<00:00, 2.23MB/s]\n",
            "100% 3.04M/3.04M [00:01<00:00, 2.73MB/s]\n",
            "Archive:  /content/stable-diffusion-image-to-prompts.zip\n",
            "  inflating: images/20057f34d.png    \n",
            "  inflating: images/227ef0887.png    \n",
            "  inflating: images/92e911621.png    \n",
            "  inflating: images/a4e1c55a9.png    \n",
            "  inflating: images/c98f79f71.png    \n",
            "  inflating: images/d8edf2e40.png    \n",
            "  inflating: images/f27825b2c.png    \n",
            "  inflating: prompts.csv             \n",
            "  inflating: sample_submission.csv   \n",
            "Output file downloaded to diffusiondb-data-cleansing/diffusiondb.csv\n",
            "Kernel log downloaded to diffusiondb-data-cleansing/diffusiondb-data-cleansing.log \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "!pip install kaggle\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "f = open(\"/content/gdrive/My Drive/Colab Notebooks/Kaggle/kaggle.json\", 'r')\n",
        "json_data = json.load(f) \n",
        "os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
        "os.environ['KAGGLE_KEY'] = json_data['key']\n",
        "\n",
        "!kaggle competitions download -c stable-diffusion-image-to-prompts\n",
        "!unzip /content/stable-diffusion-image-to-prompts.zip\n",
        "\n",
        "!mkdir diffusiondb-data-cleansing\n",
        "!kaggle kernels output shoheiazuma/diffusiondb-data-cleansing -p diffusiondb-data-cleansing\n",
        "#!mkdir /content/input\n",
        "#!mv /content/stable-diffusion-image-to-prompts.zip /content/input/stable-diffusion-image-to-prompts.zip\n",
        "#!unzip /content/input/stable-diffusion-image-to-prompts.zip -d /content/input/"
      ],
      "id": "0HwcNGJ44FRx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb9cb652"
      },
      "source": [
        "# Library"
      ],
      "id": "cb9cb652"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UtYsiHEjEvxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6a9280-ff9b-4a8d-eea3-f1106f25166e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.1+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.14.1 timm-0.6.13\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125942 sha256=b08fca80ed5ba39484567ae34f2cab3fa834b5131d953e714796cf28d3a17d48\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, transformers, sentence_transformers\n",
            "Successfully installed sentence_transformers-2.2.2 sentencepiece-0.1.98 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install timm\n",
        "!pip install sentence_transformers"
      ],
      "id": "UtYsiHEjEvxR"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f942bbda"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from scipy import spatial\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "from timm.utils import AverageMeter\n",
        "import sys\n",
        "#sys.path.append('../input/sentence-transformers-222/sentence-transformers')\n",
        "sys.path.append('./sentence-transformers-2.2.2/sentence-transformers')\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "f942bbda"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efbf935e"
      },
      "source": [
        "# Config"
      ],
      "id": "efbf935e"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9b7f198a"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    model_name = 'vit_base_patch16_224'\n",
        "    input_size = 224\n",
        "    batch_size = 64\n",
        "    num_epochs = 10\n",
        "    lr = 1e-4\n",
        "    seed = 42"
      ],
      "id": "9b7f198a"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6999f593"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(CFG.seed)"
      ],
      "id": "6999f593"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bef1b8da"
      },
      "source": [
        "# Dataset"
      ],
      "id": "bef1b8da"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f96e2f5a"
      },
      "outputs": [],
      "source": [
        "class DiffusionDataset(Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = Image.open(row['filepath'])\n",
        "        image = self.transform(image)\n",
        "        prompt = row['prompt']\n",
        "        return image, prompt\n",
        "\n",
        "\n",
        "class DiffusionCollator:\n",
        "    def __init__(self):\n",
        "        self.st_model = SentenceTransformer(\n",
        "            './sentence-transformers-2.2.2/all-MiniLM-L6-v2',\n",
        "            device='cpu'\n",
        "        )\n",
        "        # self.st_model = SentenceTransformer(\n",
        "        #     '/kaggle/input/sentence-transformers-222/all-MiniLM-L6-v2',\n",
        "        #     device='cpu'\n",
        "        # )\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        images, prompts = zip(*batch)\n",
        "        images = torch.stack(images)\n",
        "        prompt_embeddings = self.st_model.encode(\n",
        "            prompts, \n",
        "            show_progress_bar=False, \n",
        "            convert_to_tensor=True\n",
        "        )\n",
        "        return images, prompt_embeddings\n",
        "    \n",
        "    \n",
        "def get_dataloaders(\n",
        "    trn_df,\n",
        "    val_df,\n",
        "    input_size,\n",
        "    batch_size\n",
        "):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    trn_dataset = DiffusionDataset(trn_df, transform)\n",
        "    val_dataset = DiffusionDataset(val_df, transform)\n",
        "    collator = DiffusionCollator()\n",
        "    \n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = DataLoader(\n",
        "        dataset=trn_dataset,\n",
        "        shuffle=True,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=True,\n",
        "        collate_fn=collator\n",
        "    )\n",
        "    dataloaders['val'] = DataLoader(\n",
        "        dataset=val_dataset,\n",
        "        shuffle=False,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=False,\n",
        "        collate_fn=collator\n",
        "    )\n",
        "    return dataloaders"
      ],
      "id": "f96e2f5a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a47897ef"
      },
      "source": [
        "# Train"
      ],
      "id": "a47897ef"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "b45a55d4"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(y_trues, y_preds):\n",
        "    return np.mean([\n",
        "        1 - spatial.distance.cosine(y_true, y_pred) \n",
        "        for y_true, y_pred in zip(y_trues, y_preds)\n",
        "    ])"
      ],
      "id": "b45a55d4"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "51afe626"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    trn_df,\n",
        "    val_df,\n",
        "    model_name,\n",
        "    input_size,\n",
        "    batch_size,\n",
        "    num_epochs,\n",
        "    lr\n",
        "):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    dataloaders = get_dataloaders(\n",
        "        trn_df,\n",
        "        val_df,\n",
        "        input_size,\n",
        "        batch_size\n",
        "    )\n",
        "\n",
        "    model = timm.create_model(\n",
        "        model_name,\n",
        "        pretrained=True,\n",
        "        num_classes=384\n",
        "    )\n",
        "    model.set_grad_checkpointing()\n",
        "    model.to(device)\n",
        "    \n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    ttl_iters = num_epochs * len(dataloaders['train'])\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=ttl_iters, eta_min=1e-6)\n",
        "    criterion = nn.CosineEmbeddingLoss()\n",
        "    \n",
        "    best_score = -1.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_meters = {\n",
        "            'loss': AverageMeter(),\n",
        "            'cos': AverageMeter(),\n",
        "        }\n",
        "        model.train()\n",
        "        for X, y in tqdm(dataloaders['train'], leave=False):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            X_out = model(X)\n",
        "            target = torch.ones(X.size(0)).to(device)\n",
        "            loss = criterion(X_out, y, target)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            trn_loss = loss.item()\n",
        "            trn_cos = cosine_similarity(\n",
        "                X_out.detach().cpu().numpy(), \n",
        "                y.detach().cpu().numpy()\n",
        "            )\n",
        "\n",
        "            train_meters['loss'].update(trn_loss, n=X.size(0))\n",
        "            train_meters['cos'].update(trn_cos, n=X.size(0))\n",
        "\n",
        "        print('Epoch {:d} / trn/loss={:.4f}, trn/cos={:.4f}'.format(\n",
        "            epoch + 1,\n",
        "            train_meters['loss'].avg,\n",
        "            train_meters['cos'].avg))\n",
        "\n",
        "        val_meters = {\n",
        "            'loss': AverageMeter(),\n",
        "            'cos': AverageMeter(),\n",
        "        }\n",
        "        model.eval()\n",
        "        for X, y in tqdm(dataloaders['val'], leave=False):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                X_out = model(X)\n",
        "                target = torch.ones(X.size(0)).to(device)\n",
        "                loss = criterion(X_out, y, target)\n",
        "\n",
        "                val_loss = loss.item()\n",
        "                val_cos = cosine_similarity(\n",
        "                    X_out.detach().cpu().numpy(), \n",
        "                    y.detach().cpu().numpy()\n",
        "                )\n",
        "\n",
        "            val_meters['loss'].update(val_loss, n=X.size(0))\n",
        "            val_meters['cos'].update(val_cos, n=X.size(0))\n",
        "\n",
        "        print('Epoch {:d} / val/loss={:.4f}, val/cos={:.4f}'.format(\n",
        "            epoch + 1,\n",
        "            val_meters['loss'].avg,\n",
        "            val_meters['cos'].avg))\n",
        "        \n",
        "        if val_meters['cos'].avg > best_score:\n",
        "            best_score = val_meters['cos'].avg\n",
        "            torch.save(model.state_dict(), f'{model_name}.pth')"
      ],
      "id": "51afe626"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9G5YfwBlFgk5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eb8bfc66-c8cc-46cc-b59d-60caf7fee388"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            filepath  \\\n",
              "0  /kaggle/input/diffusiondb-2m-part-0001-to-0100...   \n",
              "1  /kaggle/input/diffusiondb-2m-part-0001-to-0100...   \n",
              "2  /kaggle/input/diffusiondb-2m-part-0001-to-0100...   \n",
              "3  /kaggle/input/diffusiondb-2m-part-0001-to-0100...   \n",
              "4  /kaggle/input/diffusiondb-2m-part-0001-to-0100...   \n",
              "\n",
              "                                              prompt  \n",
              "0  a portrait of a female robot made from code, v...  \n",
              "1                    dream swimming pool with nobody  \n",
              "2  a beautiful paint of cultists dancing surround...  \n",
              "3  frontal portrait of ragged, worried twin women...  \n",
              "4  a stunning portrait of an asian samurai with l...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-707e04f6-b182-452a-94d8-03e0c86782dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepath</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/kaggle/input/diffusiondb-2m-part-0001-to-0100...</td>\n",
              "      <td>a portrait of a female robot made from code, v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/kaggle/input/diffusiondb-2m-part-0001-to-0100...</td>\n",
              "      <td>dream swimming pool with nobody</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/kaggle/input/diffusiondb-2m-part-0001-to-0100...</td>\n",
              "      <td>a beautiful paint of cultists dancing surround...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/kaggle/input/diffusiondb-2m-part-0001-to-0100...</td>\n",
              "      <td>frontal portrait of ragged, worried twin women...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/kaggle/input/diffusiondb-2m-part-0001-to-0100...</td>\n",
              "      <td>a stunning portrait of an asian samurai with l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-707e04f6-b182-452a-94d8-03e0c86782dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-707e04f6-b182-452a-94d8-03e0c86782dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-707e04f6-b182-452a-94d8-03e0c86782dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df = pd.read_csv('./diffusiondb-data-cleansing/diffusiondb.csv')\n",
        "df.head()"
      ],
      "id": "9G5YfwBlFgk5"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i3Th0qCKFoc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "efe61579-1cf7-43db-d1a2-d93cc8be6aa9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            filepath  \\\n",
              "0  ./diffusiondb-2m-part-0001-to-0100-of-2000/221...   \n",
              "1  ./diffusiondb-2m-part-0001-to-0100-of-2000/48e...   \n",
              "2  ./diffusiondb-2m-part-0001-to-0100-of-2000/291...   \n",
              "3  ./diffusiondb-2m-part-0001-to-0100-of-2000/3c8...   \n",
              "4  ./diffusiondb-2m-part-0001-to-0100-of-2000/454...   \n",
              "\n",
              "                                              prompt  \n",
              "0  a portrait of a female robot made from code, v...  \n",
              "1                    dream swimming pool with nobody  \n",
              "2  a beautiful paint of cultists dancing surround...  \n",
              "3  frontal portrait of ragged, worried twin women...  \n",
              "4  a stunning portrait of an asian samurai with l...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af511bd9-0177-41a1-bd6a-3f9053dee115\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepath</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./diffusiondb-2m-part-0001-to-0100-of-2000/221...</td>\n",
              "      <td>a portrait of a female robot made from code, v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./diffusiondb-2m-part-0001-to-0100-of-2000/48e...</td>\n",
              "      <td>dream swimming pool with nobody</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./diffusiondb-2m-part-0001-to-0100-of-2000/291...</td>\n",
              "      <td>a beautiful paint of cultists dancing surround...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./diffusiondb-2m-part-0001-to-0100-of-2000/3c8...</td>\n",
              "      <td>frontal portrait of ragged, worried twin women...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./diffusiondb-2m-part-0001-to-0100-of-2000/454...</td>\n",
              "      <td>a stunning portrait of an asian samurai with l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af511bd9-0177-41a1-bd6a-3f9053dee115')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af511bd9-0177-41a1-bd6a-3f9053dee115 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af511bd9-0177-41a1-bd6a-3f9053dee115');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df.filepath = df.filepath.str.replace('/kaggle/input', '.', regex=True)\n",
        "df.head()"
      ],
      "id": "i3Th0qCKFoc8"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!mkdir ./difusiondb-data"
      ],
      "metadata": {
        "id": "J-qgZnYt9c_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83309a29-e241-41a9-cef8-fe4839816ee9"
      },
      "id": "J-qgZnYt9c_j",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.84 ms, sys: 2.32 ms, total: 5.15 ms\n",
            "Wall time: 106 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "bf = ''\n",
        "fc = 0\n",
        "#df_ = pd.DataFrame(columns=['filepath', 'prompt'])\n",
        "#diffusiondb_file_count = []\n",
        "for row in df.iterrows():\n",
        "  f = row[1]['filepath'][:34]\n",
        "  if bf != f:\n",
        "    bf = f\n",
        "    if row[0] != 0:\n",
        "#      display(df_)\n",
        "      df_ = df[fc:row[0]]\n",
        "#      display(df_)\n",
        "      pt = f'{f}/*' # ./difusiondb-data/'\n",
        "      !cp  {f}/* ./difusiondb-data/\n",
        "      trn_df, val_df = train_test_split(df_, test_size=0.1, random_state=CFG.seed)\n",
        "      train(trn_df, val_df, CFG.model_name, CFG.input_size, CFG.batch_size, CFG.num_epochs, CFG.lr)\n",
        "\n",
        "      fc = row[0]\n",
        "#      diffusiondb_file_count.append(fc)\n",
        "\n",
        "df_ = df[fc:]\n",
        "trn_df, val_df = train_test_split(df_, test_size=0.1, random_state=CFG.seed)\n",
        "train(trn_df, val_df, CFG.model_name, CFG.input_size, CFG.batch_size, CFG.num_epochs, CFG.lr)\n",
        "#display(df_)\n",
        "#      df_ = pd.DataFrame(columns=['filepath', 'prompt'])\n",
        "#      break\n",
        "#  display(row[1])\n",
        "#  df_ = pd.concat([df_, row[1]])\n",
        "#diffusiondb_file_count"
      ],
      "metadata": {
        "id": "kMqlwlhF6lv5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "b2c585a0-7f49-4443-8382-fa907ab8ebf0"
      },
      "id": "kMqlwlhF6lv5",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat './diffusiondb-2m-part-0101-to-0200/*': No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-34e5c0020945>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trn_df, val_df, model_name, input_size, batch_size, num_epochs, lr)\u001b[0m\n\u001b[1;32m      9\u001b[0m ):\n\u001b[1;32m     10\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     dataloaders = get_dataloaders(\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtrn_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-eb1ca3af5a3a>\u001b[0m in \u001b[0;36mget_dataloaders\u001b[0;34m(trn_df, val_df, input_size, batch_size)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mtrn_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiffusionDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiffusionDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mcollator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiffusionCollator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-eb1ca3af5a3a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDiffusionCollator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         self.st_model = SentenceTransformer(\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;34m'./sentence-transformers-2.2.2/all-MiniLM-L6-v2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'modules.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m#Load as SentenceTransformer model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_sbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m#Load with AutoModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_auto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m_load_sbert_model\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0mmodule_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m             \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(input_path)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msbert_config_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfIn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfIn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_name_or_path\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_name_or_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtokenizer_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self, model_name_or_path, config, cache_dir)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_t5_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_t5_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    472\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2558\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sharded\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m                 \u001b[0;31m# Time to load the checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m             \u001b[0;31m# set dtype to instantiate the model under:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_load_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'data/{key}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m         \u001b[0;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "564e150a"
      },
      "outputs": [],
      "source": [
        "trn_df, val_df = train_test_split(df, test_size=0.1, random_state=CFG.seed)"
      ],
      "id": "564e150a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37b51ad9"
      },
      "outputs": [],
      "source": [
        "# trn_df = df[:2]\n",
        "# val_df = df[2:4]\n",
        "# val_df"
      ],
      "id": "37b51ad9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6a1db70"
      },
      "outputs": [],
      "source": [
        "train(trn_df, val_df, CFG.model_name, CFG.input_size, CFG.batch_size, CFG.num_epochs, CFG.lr)"
      ],
      "id": "b6a1db70"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f74eabef"
      },
      "outputs": [],
      "source": [
        "# model = timm.create_model(\n",
        "#     CFG.model_name,\n",
        "#     pretrained=True,\n",
        "#     num_classes=384\n",
        "# )\n",
        "# model.load_state_dict(torch.load('{CFG.model_name}.pth'))\n",
        "\n",
        "# model.eval()\n",
        "# for X, y in tqdm(dataloaders['val'], leave=False):\n",
        "#     X, y = X.to(device), y.to(device)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         X_out = model(X)\n",
        "#         target = torch.ones(X.size(0)).to(device)\n",
        "#         loss = criterion(X_out, y, target)\n"
      ],
      "id": "f74eabef"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 30786.129377,
      "end_time": "2023-04-04T21:58:26.542178",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-04-04T13:25:20.412801",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}